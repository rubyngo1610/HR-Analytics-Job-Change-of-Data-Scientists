#Kyle Lee

#import the relevant libraries
import pandas as pd
import numpy as np

#import csv file
train_data = pd.read_csv('aug_train.csv')

#first 10 row of data set, describe attributes
train_data.head(10)
train_data.describe(include='all')

#looking at the type of variables in data set
train_data.dtypes

#Round all values in the variable to 3 decimal places
train_data['city_development_index'] = round(train_data['city_development_index'],3)

#look for any unique values
for look in train_data:
    print(train_data[look].unique())

# changing up categorical to dummy variables(if needed)
train_data['relevant_experience_dummies'] = pd.get_dummies(train_data['relevent_experience'])

#replacing all na values to not reported
train_data['gender'] = train_data['gender'].replace(np.NaN, "Not Reported")
train_data['enrolled-university'] = train_data['enrolled-university'].replace(np.NaN, "Not Reported")
train_data['education-level'] = train_data['education-level'].replace(np.NaN, "Not Reported")

#sort if needed
train_data.sort_values(by=['enrollee_id'],inplace = True)

#import test_data
test_data = pd.read_csv('aug_test.csv')

test_data.dtypes

#round city_development_index values to 3 decimal points
test_data['city_development_index'] = round(test_data['city_development_index'],3)

#replace na values in test_data
test_data['gender'] = test_data['gender'].replace(np.NaN, "Not Reported")
test_data['enrolled-university'] = test_data['enrolled-university'].replace(np.NaN, "Not Reported")
test_data['education-level'] = test_data['education-level'].replace(np.NaN, "Not Reported")


#Ruby

#Import packages
import pandas as pd
import numpy as np
import pandasql as sql

#Read the train data
train_data = pd.read_csv('aug_train.csv')

#Take a look at the first 10 rows of the dataset
train_data.head(10)

#Summarize the data
train_data.describe(include='all')

#Identify the data types of every data point
train_data.dtypes

#Count the NAs in the train data
train_data.isnull().sum()

#Drop those who are missing information about their experience
train_data = train_data.dropna(subset=['experience'])

#look specifically at the enrolled_university, education_level, and the major_discipline data
q = """
    select enrolled_university, education_level, major_discipline
    from train_data
    WHERE major_discipline is null;
    """
    
#Execute your SQL command against the pandas frame
sql.sqldf(q.lower(), locals()).head(15)
#All of those who don't have a major_discipline were undergrad students or did not attend college

#Look for mispelled values or labels
for i in train_data:
    print(train_data[i].unique())
    
#Handle the NAs
train_data["gender"] = train_data["gender"].fillna("Not Reported")
train_data["major_discipline"] = train_data[train_data.enrolled_university == "no_enrollment"]["major_discipline"].fillna("No Major")
train_data["major_discipline"] = train_data["major_discipline"].fillna("Not Reported")
train_data["company_size"] = train_data["company_size"].fillna("Not Reported")
train_data["company_type"] = train_data["company_type"].fillna("Not Reported")
train_data["last_new_job"] = train_data["last_new_job"].fillna("Not Reported")

#Make the labels' form in company_size consistent
train_data["company_size"] = train_data["company_size"].replace("10/49","10-49")

#Transform the experience's data
train_data['experience'] = train_data['experience'].replace(["1","2","3","4","5"],"1-5")
train_data['experience'] = train_data['experience'].replace(["6","7","8","9","10"],"6-10")
train_data['experience'] = train_data['experience'].replace(["11","12","13","14","15"],"11-15")
train_data['experience'] = train_data['experience'].replace(["16","17","18","19","20"],"16-20")
